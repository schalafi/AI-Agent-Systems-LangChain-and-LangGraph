{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Simple LLM Calls - STARTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your first hands-on experience with Large Language Models! \n",
    "\n",
    "In this exercise, you'll learn how to interact with an LLM programmatically using the OpenAI SDK. This is your gateway to building applications that harness the power of AI for generating text, automating tasks, and solving complex problems. Whether you're aiming to integrate AI into a product or just exploring its potential, this exercise will give you the foundational skills to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "You are tasked with creating an application that helps Marketing Analysts with creating content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiate OpenAI client with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an OpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "client = OpenAI(api_key=\"voc-\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables using os.getenv()\n",
    "#api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(f\"API Key: {api_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Instantiate your client\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Use the OPENAI_API_KEY \n",
    "client = OpenAI( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define important parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To effectively call the API, it's important to define some important parameters.\n",
    "- model: the specific LLM you want to call. We'll be using gpt-4o-mini.\n",
    "- temperature: how random you want the responses to be. It ranges from 0.0 to 1.0. Values more close to 1.0 let the LLM be more creative, while values close to 0.0 let it be more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - create a variable called model with \"gpt-4o-mini\" as value\n",
    "model =\"gpt-4.1-nano\" #\"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - create a variable called temperature with some float \n",
    "# value ranging from 0.0 to 2.0\n",
    "import numpy as np \n",
    "\n",
    "temperature = np.arange(0,2+0.1, 0.1)\n",
    "temperature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tell the model how to behave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most powerful parameter is system prompt. It enables you to instruct how you want the LLM to behave. It's important to write a clear, concise instruction for the LLM.\n",
    "\n",
    "Suppose you work for a fictitious B2B company which developed a benefits card for companies to offer their employees more cultural experiences, such as Museums, Art Galleries, Concerts, etc.\n",
    "\n",
    "- For this exercise, the prompt should be specific enough to guide the LLM towards the desired output (B2B content about CultPass)\n",
    "- But also flexible enough to handle a range of industries (target) and channels (email, instagram, tiktok...)\n",
    "\n",
    "Example:\n",
    "```python\n",
    "system_prompt = \"Act as a B2B content creator for a company called CultPass.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - create a variable called system_prompt with \n",
    "# any instruction text.\n",
    "system_prompt =  \"Act as a B2B content creator for a company called CultPass.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a function to reuse LLM calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have all the parameters, you need to accept the user input to send to OpenAI API.\n",
    "\n",
    "To accept it, add a new element to the `messages` list inside the `create_content` function. It's a dictionary similar to the first element, but this time the role is `user`.\n",
    "\n",
    "Remember, the structure is the following:\n",
    "```python\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "print(response.choices[0].message.content)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_content(query:str,\n",
    "                   client:OpenAI, \n",
    "                   system_prompt:str,\n",
    "                   model:str,\n",
    "                   temperature:float)->str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        # TODO - marketing analyst query\n",
    "        {\"role\": \"user\", \"content\":query}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    # Experiment returning the full response to understand the object\n",
    "    #content = response.choices[0].message.content\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Call `create_content` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marketing Analyst input\n",
    "analyst_query = \"Create an instagram post for clients in the automotive industry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = create_content(\n",
    "    query=analyst_query,\n",
    "    # TODO - pass the other arguments\n",
    "    client = client,\n",
    "    system_prompt = system_prompt,\n",
    "    model = model,\n",
    "    temperature = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you understood how it works, experiment with new things.\n",
    "\n",
    "- Change the temperature of the model\n",
    "- Change the system prompt\n",
    "- Change the user query to other channels and industries\n",
    "- Inspect the objects returned by OpenAI, what else you can get out of it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
